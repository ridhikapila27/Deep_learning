{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWNvwk1r1OOHoNXPHHXRUw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ridhikapila27/Deep_learning/blob/main/Lab7_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "Jx5uzh8_Uenb"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set layer parameters\n",
        "input_size = 9 # number of features to extract (e.g., number of data channels)\n",
        "hidden_size = 16 # number of units in the hidden state\n",
        "num_layers = 1 # number of vertical stacks of hidden layers (note: only the final layer gives an output)\n",
        "actfun = 'tanh'\n",
        "bias = True\n",
        "# create an RNN instance\n",
        "rnn = nn.RNN(input_size,hidden_size,num_layers,nonlinearity=actfun,bias=bias)\n",
        "print(rnn)\n",
        "# check out the source code for more detailed info about this class\n",
        "??nn.RNN\n",
        "# set data parameters\n",
        "seqlength = 5\n",
        "batchsize = 2\n",
        "# create some data\n",
        "X = torch.rand(seqlength,batchsize,input_size)\n",
        "# create a hidden layer (typically initialized as zeros)\n",
        "hidden = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "# run some data through the model and show the output sizes\n",
        "y,h = rnn(X,hidden)\n",
        "print(f' Input shape: {list(X.shape)}')\n",
        "print(f'Hidden shape: {list(h.shape)}')\n",
        "print(f'Output shape: {list(y.shape)}')\n",
        "## Default hidden state is all zeros if nothing specified:\n",
        "y,h1 = rnn(X,hidden)\n",
        "print(h1), print('\\n\\n')\n",
        "y,h2 = rnn(X)\n",
        "print(h2), print('\\n\\n')\n",
        "# they're the same! (meaning default=zeros)\n",
        "print(h1-h2)\n",
        "# Check out the learned parameters and their sizes\n",
        "for p in rnn.named_parameters():\n",
        "  if 'weight' in p[0]:\n",
        "     print(f'{p[0]} has size {list(p[1].shape)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq6HJLYnUkiT",
        "outputId": "ebc30a03-0de2-4fed-b606-78d5c2e48ef1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN(9, 16)\n",
            " Input shape: [5, 2, 9]\n",
            "Hidden shape: [1, 2, 16]\n",
            "Output shape: [5, 2, 16]\n",
            "tensor([[[ 0.2264, -0.1959, -0.8311, -0.2815,  0.0598,  0.2627, -0.5895,\n",
            "           0.3471,  0.5590,  0.4906,  0.0392, -0.4393, -0.0219, -0.0845,\n",
            "           0.5504,  0.3714],\n",
            "         [ 0.3592,  0.0555, -0.6684, -0.5904,  0.0446, -0.0311, -0.5923,\n",
            "          -0.1613,  0.5936,  0.3147,  0.0308, -0.4747, -0.3216, -0.4296,\n",
            "           0.5624,  0.3183]]], grad_fn=<StackBackward0>)\n",
            "\n",
            "\n",
            "\n",
            "tensor([[[ 0.2264, -0.1959, -0.8311, -0.2815,  0.0598,  0.2627, -0.5895,\n",
            "           0.3471,  0.5590,  0.4906,  0.0392, -0.4393, -0.0219, -0.0845,\n",
            "           0.5504,  0.3714],\n",
            "         [ 0.3592,  0.0555, -0.6684, -0.5904,  0.0446, -0.0311, -0.5923,\n",
            "          -0.1613,  0.5936,  0.3147,  0.0308, -0.4747, -0.3216, -0.4296,\n",
            "           0.5624,  0.3183]]], grad_fn=<StackBackward0>)\n",
            "\n",
            "\n",
            "\n",
            "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
            "       grad_fn=<SubBackward0>)\n",
            "weight_ih_l0 has size [16, 9]\n",
            "weight_hh_l0 has size [16, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNnet(nn.Module):\n",
        "  def __init__(self,input_size,num_hidden,num_layers):\n",
        "    super().__init__()\n",
        "    # store parameters\n",
        "    self.input_size = input_size\n",
        "    self.num_hidden = num_hidden\n",
        "    self.num_layers = num_layers\n",
        "    # RNN Layer\n",
        "    self.rnn = nn.RNN(input_size,num_hidden,num_layers)\n",
        "    # linear layer for output\n",
        "    self.out = nn.Linear(num_hidden,1)\n",
        "    def forward(self,x):\n",
        "      print(f'Input: {list(x.shape)}')\n",
        "      # initialize hidden state for first input\n",
        "      hidden = torch.zeros(self.num_layers,batchsize,self.num_hidden)\n",
        "      print(f'Hidden: {list(hidden.shape)}')\n",
        "      # run through the RNN layer\n",
        "      y,hidden = self.rnn(x,hidden)\n",
        "      print(f'RNN-out: {list(y.shape)}')\n",
        "      print(f'RNN-hidden: {list(hidden.shape)}')\n",
        "      # pass the RNN output through the linear output layer\n",
        "      o = self.out(y)\n",
        "      print(f'Output: {list(o.shape)}')\n",
        "      return o,hidden\n",
        "  # create an instance of the model and inspect\n",
        "    net = RNNnet(input_size,hidden_size,num_layers)\n",
        "    print(net), print(' ')\n",
        "    # and check out all learnable parameters\n",
        "    for p in net.named_parameters():\n",
        "      print(f'{p[0]} has size {list(p[1].shape)}')\n",
        "      # test the model with some data\n",
        "      # create some data\n",
        "      X = torch.rand(seqlength,batchsize,input_size)\n",
        "      y = torch.rand(seqlength,batchsize,1)\n",
        "      yHat,h = net(X)\n",
        "      # try a loss function\n",
        "      lossfun = nn.MSELoss()\n",
        "      lossfun(yHat,y)"
      ],
      "metadata": {
        "id": "YsYkr-_bUz91"
      },
      "execution_count": 39,
      "outputs": []
    }
  ]
}